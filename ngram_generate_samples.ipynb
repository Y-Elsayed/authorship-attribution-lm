{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\Yassin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Yassin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Yassin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Yassin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Yassin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Yassin\\AppData\\Local\\Temp\\ipykernel_68416\\1892073495.py\", line 1, in <module>\n",
      "    from data_processor import DataProcessor\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\data_processor.py\", line 2, in <module>\n",
      "    import spacy\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\thinc\\types.py\", line 25, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from data_processor import DataProcessor\n",
    "import ngram_authorship_classifier as nac\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"The lady\", \"he thought\", \"I cannot\", \"she was\", \"the world\" ]\n",
    "\n",
    "author_prompt = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"ngram_authorship_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yassin\\Desktop\\NLP\\Homeworks\\HW3\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for author: Austen\n",
      "Processing data for author: Dickens\n",
      "Processing data for author: Tolstoy\n",
      "Processing data for author: Wilde\n"
     ]
    }
   ],
   "source": [
    "author_files = [\"austen_utf8.txt\",\"dickens_utf8.txt\",\"tolstoy_utf8.txt\",\"wilde_utf8.txt\"]\n",
    "author_names = [\"Austen\",\"Dickens\",\"Tolstoy\",\"Wilde\"]\n",
    "\n",
    "data_proc = DataProcessor()\n",
    "\n",
    "authors_train_data = dict()\n",
    "authors_test_data = dict()\n",
    "for i in range(len(author_files)):\n",
    "    print(\"Processing data for author: \" + author_names[i])\n",
    "    trainset,_ = data_proc.process_file(os.path.join(data_dir, author_files[i]))\n",
    "    authors_train_data[author_names[i]] = trainset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nac.NgramAuthorshipClassifier(n=1, smoothing = 'lp')\n",
    "model2 = nac.NgramAuthorshipClassifier(n=2, smoothing = 'lp')\n",
    "model3 = nac.NgramAuthorshipClassifier(n=3, smoothing = 'lp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Unigram Model...\n",
      "Training LMs... (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Unigram Model...\")\n",
    "model1.train(authors_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bigram Model...\n",
      "Training LMs... (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Bigram Model...\")\n",
    "model2.train(authors_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Trigram Model...\n",
      "Training LMs... (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Trigram Model...\")\n",
    "model3.train(authors_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samples function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_text(authors, prompts,model):\n",
    "    return model.generate_authors_text(authors = authors,prompts= prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample text for Unigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating sample text for Unigram Model...\")\n",
    "model1_text = generate_sample_text(author_names,prompts,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample text for Bigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating sample text for Bigram Model...\")\n",
    "model2_text = generate_sample_text(author_names,prompts,model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample text for Trigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating sample text for Trigram Model...\")\n",
    "model3_text = generate_sample_text(author_names,prompts,model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_text(text_dict, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(text_dict, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generated text for Unigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving generated text for Unigram Model...\")\n",
    "save_generated_text(model1_text, \"model1_text.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Austen': [{'text': 'The lady her for deal , some all hither as been being boils . is it proceeded , inconsistency ” shall entirely', 'perplexity': 669.5937747814957}, {'text': 'he thought constant he far given every of and not \" attentive but Emma serenity be sure with and uncertain the offering', 'perplexity': 691.6810353763215}, {'text': 'I cannot this . sanguine however their . time continually been think had way continued involuntarily the that may malicious which he', 'perplexity': 908.5703650491848}, {'text': 'she was was Catherine some either unconscious week same But Illustration very my contempt many be , injured , at therefore subject', 'perplexity': 900.5631109927606}, {'text': 'the world , mean “ can invite day see over might your preceding can deserve not pause a the giving something .', 'perplexity': 717.2156407740298}], 'Dickens': [{'text': 'The lady hand at in the , water had , did ’ stopped adopted a so with . afore women stuffed a', 'perplexity': 452.51708064922394}, {'text': 'he thought do the her great a on accident ’ a ‘ . from it you though as not to I the', 'perplexity': 181.1429259254108}, {'text': 'I cannot replacing light trying I world was Murdstone of winding You take his has to qualified care somebody Darnay wife These', 'perplexity': 2023.2144708940955}, {'text': 'she was ? neatly stony , know was bring , ’ enraptured that rank favour ’ with , , well frenzy ,', 'perplexity': 530.0466110350985}, {'text': 'the world Hardly my believe , it in . you denial remember many her taken to the aunt ’ by that been', 'perplexity': 379.51877695916005}], 'Tolstoy': [{'text': 'The lady Marya could That begin wagon , the represented , , labor was forgive shall there ” of disliked sorry mounted', 'perplexity': 1042.32263463535}, {'text': 'he thought scythe still left it would of not . free his That heartily the He daughter , so Seryozha , and', 'perplexity': 386.2022390722055}, {'text': 'I cannot went As talk eyes voices who she Andrew Kurágin was not day men bees , is , back though that', 'perplexity': 883.5435522413593}, {'text': 'she was long gave magic Would the the one I in by and you ” , to natural dress as pity have', 'perplexity': 394.5782021760949}, {'text': 'the world this self . her realized attempting How coming the the to clutching lavished and in into had face expressed to', 'perplexity': 643.881520496815}], 'Wilde': [{'text': 'The lady , that seemed the I better . of changing out original of burned folds began , lad went incapable abandonment', 'perplexity': 890.5328029983082}, {'text': 'he thought about name it ; ten brought should always killed the me A place When Charming tears Romeo apprehension , to', 'perplexity': 982.2519275000345}, {'text': 'I cannot meaningless ecstasy Except It mats horrible a honour . very told it a Somebody delicate Hughie art oaths so Milan', 'perplexity': 2937.9614883836057}, {'text': 'she was expressions I , see saw is me set W. one eyes in , Mertons his remembrance . the , ,', 'perplexity': 343.2046256128598}, {'text': 'the world simple in at sucking them room that the and treasure put Vienna Gray I you Of towards your is .', 'perplexity': 644.4602777607075}]}\n"
     ]
    }
   ],
   "source": [
    "print(model1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generated text for Bigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving generated text for Bigram Model...\")\n",
    "save_generated_text(model2_text, \"model2_text.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Austen': [{'text': 'The lady ; ( repeating something remarkable . Elinor submitted to me see . ” </s> table , and kindness added ,', 'perplexity': 1039.0613725364856}, {'text': 'he thought of such paradings again on together , her visit the two Miss Fairfax . Lady Elliott , and cucumber .', 'perplexity': 1069.0987028813754}, {'text': 'I cannot -- from Jane ’s happiness must be made me ! To congratulate you were , by distinguishing the mistake ,', 'perplexity': 1424.0489232738873}, {'text': 'she was joy , though some danger.--Perhaps this time , that I care and did speak than to say , however ,', 'perplexity': 670.4799432741034}, {'text': 'the world . But such a mode of the others were her to be coming hither , because you believe he is', 'perplexity': 641.0832730008497}], 'Dickens': [{'text': 'The lady as our departure in reversion -- saving that , sir , father . The fact ( it . Is sought', 'perplexity': 1630.9020845360687}, {'text': 'he thought , or your breath to be hanged there are quite a sturdy beggar . </s> freed . My wind ,', 'perplexity': 1571.2628380120946}, {'text': 'I cannot ‘ Oh , that the Last Day were only the sport of easy - breadth line of her feet became', 'perplexity': 1954.8911355628666}, {'text': 'she was agitated pause , tenderly adjusting some other , ’ said Mr. Micawber should not that you will bear , appeared', 'perplexity': 995.5130444808474}, {'text': 'the world , by the latter days past -- come about this life he had never been walking exercise I ’d have', 'perplexity': 1528.6383734659246}], 'Tolstoy': [{'text': 'The lady , a uniform , with Stremov at a frightened and Major Ekonómov , of marriage . </s> ? Either she', 'perplexity': 1594.686683109685}, {'text': 'he thought Levin often do to him . “ Why so on a horse Kutúzov with Berg who did not only so', 'perplexity': 761.0648185543157}, {'text': 'I cannot now giving you off her relations , are cultivating their highest stage of her for blood , entering into her', 'perplexity': 2931.061288893808}, {'text': 'she was what I would go ? Why not to deceive himself in which with a glaring example , and lighthearted gaiety', 'perplexity': 937.7180639984683}, {'text': 'the world , he knew the wit Shinshín in the smile with the ladies rose and heaved a retired . My treasure', 'perplexity': 1437.2839077638894}], 'Wilde': [{'text': 'The lady , — the gamekeeper . No one ’s description of ancient chivalry , yes , and women were impossible !', 'perplexity': 1878.9593996395652}, {'text': 'he thought at him that came the duchess for your moods and put the weather , not good . You led .', 'perplexity': 1359.4683451536607}, {'text': 'I cannot a mood of brain . </s> be sure you go to the spiritual ecstasies of France , with the Tapestry', 'perplexity': 1614.1758694465377}, {'text': 'she was of the best thing is not yet revealed his feelings were beyond his head in love or fair mirrours of', 'perplexity': 1523.519480509499}, {'text': 'the world must see till five years matter beyond which it as a citizen of a conspiracy against you will say things', 'perplexity': 1850.1843379123482}]}\n"
     ]
    }
   ],
   "source": [
    "print(model2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generated text for Trigram Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving generated text for Trigram Model...\")\n",
    "save_generated_text(model3_text, \"model3_text.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Austen': [{'text': 'The lady is Mrs. Dixon , you know , and the agreeableness of yesterday ’s engagement , assisted too as you know', 'perplexity': 2068.6758418243526}, {'text': 'he thought he looked a little land and build one myself , though rather longer , for Mr. Weston . They saw', 'perplexity': 3380.500586009938}, {'text': 'I cannot -- I thank you . They entered the room in it less than _ half _ the present concern .', 'perplexity': 3189.4300190216354}, {'text': 'she was considered by the over - powered . Such language for a second young Cox , and quicker , that Mr.', 'perplexity': 3609.273690687399}, {'text': 'the world , for she did think there are not much reason to wish to have the means . We were always', 'perplexity': 2332.23965692384}], 'Dickens': [{'text': 'The lady at this time drawn the chair , looking on the box - door into my bedroom window , refreshing his', 'perplexity': 4437.507382284129}, {'text': 'he thought about it . “ Him and his head , who never looks at me for a moment without speaking ,', 'perplexity': 3249.047528821136}, {'text': 'I cannot parting visit to Blunderstone , as important above all , for we have actually a run of confidence , and', 'perplexity': 4504.80356532126}, {'text': 'she was passionate . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>', 'perplexity': 6220.78827543645}, {'text': 'the world but to leave , making as if by accident , I speak of success in his misery ! ” Then', 'perplexity': 4182.795547157464}], 'Tolstoy': [{'text': 'The lady smiled a strange thing ; why not ? ” Rostóv kept asking as he collected the tickets from all sides', 'perplexity': 4222.697432138681}, {'text': 'he thought , and her pride in her difficulty in realizing what they called the colonel . “ But , ” he', 'perplexity': 2406.8365331720047}, {'text': 'I cannot now be carried out , ” replied Alexey Alexandrovitch ’s power , had returned to Alexey Alexandrovitch ’s power ,', 'perplexity': 3245.988985983899}, {'text': 'she was with God ! everything ’s over with him , now that from the strain of thought had sprung up again', 'perplexity': 4216.888673972758}, {'text': 'the world , there is some peculiar way . I know , Mary , looking just as quietly , and I ’m', 'perplexity': 3189.98097216586}], 'Wilde': [{'text': 'The lady is dead . ” </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>', 'perplexity': 4053.3667506688457}, {'text': 'he thought Cyril effeminate .   ‘ Upon the walls .   It sounded like a wooden bench that was coaling .', 'perplexity': 5202.997400374419}, {'text': 'I cannot , with terror , and proud , and the world had sought to “ Tannhauser ” and “ by the', 'perplexity': 3456.6399100620074}, {'text': 'she was seventeen . I was bored . ” </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>', 'perplexity': 3368.8350565172955}, {'text': 'the world all about the objective existence of the unlucky beater , shot in the list of all his shame . </s>', 'perplexity': 4386.75620092468}]}\n"
     ]
    }
   ],
   "source": [
    "print(model3_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
